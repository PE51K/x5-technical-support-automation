{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25ad292",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb8d04f9-8d51-42b4-a610-4c8c79ee4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bezgin.aleksey3/seara_text_encoder/train_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"deepvk/USER-bge-m3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06369f1f-60f4-4a7c-9223-91db1ea56d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.read_csv('qa_df_ready_splits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f40b8c40-16dc-472f-b748-47693c33b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = qa_df[qa_df.split == 'train']\n",
    "val_df = qa_df[qa_df.split == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d66b403b-ce51-4551-8a58-9fa7a8747442",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97eba04a-a5ac-4c6a-bcfd-d5551f814da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1423, 7), (352, 7))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "112a1287-6a57-45bf-be31-23044c298e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. заполнить бд - есть\n",
    "# 2. поднять эмбеддер - в процессе \n",
    "# 3. поднять пайплайн поиска - в процессе\n",
    "# 4. попробовать реранк - потом\n",
    "# 5. попробовать потретить retrieval модель - пробуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cb4885a-b137-492b-b2db-2ed7933dccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_in_batches(texts, batch_size=16):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs.to(model.device))\n",
    "        batch_embeddings = outputs[0][:, 0, :].detach().cpu()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a45f9cd-f723-4884-b2db-67fe8a24ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_recall_topn(model, tokenizer, train, val, \n",
    "                      q_column='question_clear', a_column='content_clear', \n",
    "                      batch_size=128, topn=10):    \n",
    "    train = train.reset_index(drop=True)\n",
    "    val = val.reset_index(drop=True)\n",
    "    \n",
    "    # topn = 10\n",
    "    # q_column = 'question_clear'\n",
    "    # a_column = 'content_clear'\n",
    "    \n",
    "    train_embeddings = generate_embeddings_in_batches(train[q_column].tolist(), batch_size)\n",
    "    test_embeddings = generate_embeddings_in_batches(val[q_column].tolist(), batch_size)\n",
    "    \n",
    "    top_n_matches = []\n",
    "    for test_embedding in tqdm(test_embeddings):\n",
    "        cosine_scores = cosine_similarity(test_embedding.unsqueeze(0), train_embeddings)[0]\n",
    "        top_results = torch.topk(torch.tensor(cosine_scores), topn)\n",
    "        top_n_matches.append(top_results.indices.numpy())\n",
    "    \n",
    "    accuracy_count = 0\n",
    "    unique_answers = []\n",
    "    position_found = []\n",
    "    \n",
    "    for i, indices in enumerate(top_n_matches):\n",
    "        truth_content = val.iloc[i][a_column]\n",
    "        pred_content = train[train.index.isin(indices)][a_column]\n",
    "    \n",
    "        if truth_content in pred_content.values:\n",
    "            accuracy_count += 1\n",
    "            position_found.append((pred_content.values == truth_content).argmax())\n",
    "            \n",
    "        else:\n",
    "            position_found.append(-1)\n",
    "            \n",
    "        unique_answers.append(pred_content.nunique())\n",
    "        \n",
    "    recall_topn = accuracy_count / len(top_n_matches)\n",
    "    \n",
    "    return recall_topn, unique_answers, position_found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9accd5a2-afcd-4bd7-a5b4-142604e0d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')\n",
    "\n",
    "# for topn in range(1, 11):\n",
    "#     recall_topn, unique_answers, position_found = count_recall_topn(model, tokenizer, train_df, val_df, \n",
    "#                                                                     q_column='question_clear', a_column='content_clear', \n",
    "#                                                                     batch_size=128, topn=topn)\n",
    "#     print(f\"recall@{topn} = {recall_topn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c908b7-9015-4721-95f7-6899358fccc4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb67ac6-ce16-419b-a36a-d9e41b013eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c3883f-90c7-4505-a90d-6e740bf3c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.groups = df.groupby('content_clear').groups\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.df.iloc[idx]\n",
    "        content = anchor['content_clear']\n",
    "        \n",
    "        # Positive sample: same content_clear but different query_clear\n",
    "        group = self.groups[content]\n",
    "\n",
    "        try:\n",
    "            positive_idx = random.choice(group[group != idx])\n",
    "        except IndexError:\n",
    "            positive_idx = idx\n",
    "\n",
    "        # while positive_idx == idx:\n",
    "            # positive_idx = random.choice(self.groups[content])\n",
    "        \n",
    "        positive = self.df.iloc[positive_idx]\n",
    "        \n",
    "        # Negative sample: different content_clear\n",
    "        negative_content = random.choice(list(set(self.groups.keys()) - {content}))\n",
    "        negative_idx = random.choice(self.groups[negative_content])\n",
    "        negative = self.df.iloc[negative_idx]\n",
    "        \n",
    "        anchor_input = self.tokenizer(anchor['question_clear'], padding='max_length', truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "        positive_input = self.tokenizer(positive['question_clear'], padding='max_length', truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "        negative_input = self.tokenizer(negative['question_clear'], padding='max_length', truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            'anchor_input_ids': anchor_input['input_ids'].squeeze(0),\n",
    "            'anchor_attention_mask': anchor_input['attention_mask'].squeeze(0),\n",
    "            'positive_input_ids': positive_input['input_ids'].squeeze(0),\n",
    "            'positive_attention_mask': positive_input['attention_mask'].squeeze(0),\n",
    "            'negative_input_ids': negative_input['input_ids'].squeeze(0),\n",
    "            'negative_attention_mask': negative_input['attention_mask'].squeeze(0),\n",
    "        }\n",
    "\n",
    "class TripletLossModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TripletLossModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.loss = nn.TripletMarginLoss(margin=0.5)\n",
    "\n",
    "    def forward(self, anchor_input, positive_input, negative_input):\n",
    "        anchor_emb = self._get_embedding(anchor_input)\n",
    "        positive_emb = self._get_embedding(positive_input)\n",
    "        negative_emb = self._get_embedding(negative_input)\n",
    "\n",
    "        loss = self.loss(anchor_emb, positive_emb, negative_emb)\n",
    "        return loss\n",
    "    \n",
    "    def _get_embedding(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        cls_embedding = outputs[0][:, 0, :]\n",
    "        return cls_embedding\n",
    "\n",
    "def train_and_validate(model, train_loader, train, val, optimizer, device, topn=10, epochs=5):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    max_recall = 0.90625\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            anchor_input = {\n",
    "                'input_ids': batch['anchor_input_ids'].to(device),\n",
    "                'attention_mask': batch['anchor_attention_mask'].to(device)\n",
    "            }\n",
    "            positive_input = {\n",
    "                'input_ids': batch['positive_input_ids'].to(device),\n",
    "                'attention_mask': batch['positive_attention_mask'].to(device)\n",
    "            }\n",
    "            negative_input = {\n",
    "                'input_ids': batch['negative_input_ids'].to(device),\n",
    "                'attention_mask': batch['negative_attention_mask'].to(device)\n",
    "            }\n",
    "\n",
    "            loss = model(anchor_input, positive_input, negative_input)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        test_recall_topn, _, _ = count_recall_topn(model, tokenizer, train, val)\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        if test_recall_topn > max_recall:\n",
    "            max_recall = test_recall_topn\n",
    "            torch.save(model.state_dict(), f\"triplet_model_{max_recall}.pth\")\n",
    "        \n",
    "        print(f\"epoch {epoch + 1}/{epochs}: test recall@10 = {test_recall_topn}\")\n",
    "        print(f\"epoch {epoch + 1}/{epochs}: train loss = {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518be726-7bf3-4235-9308-ff3704424020",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(train_df, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a38d46-bd6d-44ed-94b6-26ceae124814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda:0'\n",
    "\n",
    "triplet_model = TripletLossModel(model)\n",
    "optimizer = torch.optim.AdamW(triplet_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f0390b-f0c1-49d6-97f0-b564a205c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [05:00<00:00,  1.69s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.38it/s]\n",
      "100%|██████████| 352/352 [00:01<00:00, 184.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5: test recall@10 = 0.90625\n",
      "epoch 1/5: train loss = 0.10918871137533295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [05:00<00:00,  1.69s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.44it/s]\n",
      "100%|██████████| 352/352 [00:01<00:00, 219.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/5: test recall@10 = 0.9147727272727273\n",
      "epoch 2/5: train loss = 0.06251984796999546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [04:59<00:00,  1.68s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.45it/s]\n",
      "100%|██████████| 352/352 [00:01<00:00, 214.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/5: test recall@10 = 0.9204545454545454\n",
      "epoch 3/5: train loss = 0.05067158749933993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [04:59<00:00,  1.68s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.46it/s]\n",
      "100%|██████████| 352/352 [00:01<00:00, 183.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/5: test recall@10 = 0.8977272727272727\n",
      "epoch 4/5: train loss = 0.036057067553648785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [05:00<00:00,  1.69s/it]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.47it/s]\n",
      "100%|██████████| 352/352 [00:01<00:00, 180.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/5: test recall@10 = 0.8863636363636364\n",
      "epoch 5/5: train loss = 0.02622495407468817\n"
     ]
    }
   ],
   "source": [
    "train_and_validate(triplet_model, train_dataloader, train_df, val_df, optimizer, device, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2b112-e5f8-4004-b7ba-009373572698",
   "metadata": {},
   "source": [
    "## Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "225001ed-06a3-430a-acfe-4b1b7740fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "model_name = \"deepvk/USER-bge-m3\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba3459fb-9b2d-4e94-97b2-99f0e6fdff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"triplet_model_0.9204545454545454.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5da9ba90-c2bc-4355-94fd-5945dae708d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model and tokenizer\n",
    "# save_path = \"USER-bge-m3-x5\"\n",
    "# model.save_pretrained(save_path)\n",
    "# tokenizer_bge.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9dd628dd-cc58-4d2d-8156-4f48f54fde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "transformer = models.Transformer(model_name)\n",
    "pooling = models.Pooling(transformer.get_word_embedding_dimension(), pooling_mode=\"cls\")\n",
    "sentence_model = SentenceTransformer(modules=[transformer, pooling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5be1cf2b-8cfc-4627-a734-ed47195439e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 8192, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed82b92-a7a5-49b4-843a-e7b211ad90a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.44G/1.44G [00:49<00:00, 29.0MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/elderberry17/USER-bge-m3-x5-sentence/commit/86d65c0a1866d4790011f4613e54cb7ad5959151'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "login(token=\"\")\n",
    "sentence_model.push_to_hub(\"elderberry17/USER-bge-m3-x5-sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb9a6e",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e7c2d53-d420-456c-ba4c-78aba8f6f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d43affa4-88a1-44b1-aa19-8656b9a79c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('qa_for_test.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f847dce-a01e-4daf-9f12-1810b07513c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_last12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c2b9fe2-aa9a-4855-a3d0-b9a3bd7e982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_last12 = df.tail(12).answer.values\n",
    "df.loc[110-12:, 'category'] = categories_last12\n",
    "df = df.drop('answer', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "859ec671-68e5-4707-8556-736ef9ba02b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "old_question    0\n",
       "question        0\n",
       "old_answer      0\n",
       "category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a788402a-aec4-4acf-929a-bb6f77b0f63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['old_question', 'question', 'old_answer', 'category'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cc6c404-069a-4236-8a68-7f224238c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for cat in df.category.unique():\n",
    "    df_cat = df[df.category == cat]\n",
    "    df_cat = df_cat.drop_duplicates(subset=['old_answer'])\n",
    "    df_list.append(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01968c67-79aa-441f-bb72-6d251f765d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9dbddd1-6b21-4596-a464-15a98b764a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5c28637-64d8-4d9f-a9f7-11d846ad0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('qa_for_test_short.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e092d52-6bfa-4c00-a6fe-4ce21aa38016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_question</th>\n",
       "      <th>question</th>\n",
       "      <th>old_answer</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>не отображается автомобиль в личном кабинете.</td>\n",
       "      <td>Почему автомобиль не показывается в личном каб...</td>\n",
       "      <td>для внесения данных по личному автомобилю обра...</td>\n",
       "      <td>автомобиль</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    old_question  \\\n",
       "0  не отображается автомобиль в личном кабинете.   \n",
       "\n",
       "                                            question  \\\n",
       "0  Почему автомобиль не показывается в личном каб...   \n",
       "\n",
       "                                          old_answer    category  \n",
       "0  для внесения данных по личному автомобилю обра...  автомобиль  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0839340e-7d57-4d94-89bc-b159ed6ea979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_question</th>\n",
       "      <th>question</th>\n",
       "      <th>old_answer</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [old_question, question, old_answer, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new.old_question == 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d090750f-5530-490d-be7a-ba22f70ba935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('qa_for_test_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1cf5d52e-8f72-485c-840e-db7988793c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['old_question', 'question', 'old_answer', 'category'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_venv",
   "language": "python",
   "name": "train_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
