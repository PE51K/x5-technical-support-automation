include:
  - path: "docker-compose.langfuse.yaml"
    env_file: "./env/.env.langfuse"

services:
  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant/storage:/qdrant/storage

  llm:
    image: vllm/vllm-openai:latest
    ports:
      - "8000:8000"
    volumes:
      - ./data/llm/vllm/.cache/huggingface:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    command: >-
      --model ${LLM_MODEL_NAME-"Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24"}
      --dtype half
      --api-key ${LLM_API_KEY-"token-123"}
      --gpu-memory-utilization 0.60
      --max-model-len 4096

  embedder:
    image: vllm/vllm-openai:latest
    ports:
      - "8001:8000"
    volumes:
      - ./data/embedder/vllm/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HF_HUB_ENABLE_HF_TRANSFER=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    command: --model ${EMBEDDER_MODEL_NAME-elderberry17/USER-bge-m3-x5-sentence}

  app:
    build:
      context: .
    ports:
      - "${FASTAPI_PORT-5555}:${FASTAPI_PORT-5555}"
    expose:
      - "${FASTAPI_PORT-5555}"
    env_file:
      - ./env/.env
    depends_on:
      - llm
      - embedder
      - qdrant
      - langfuse-web
    restart: unless-stopped
